# AdaMuon
This is the official repository for the paper [AdaMuon: Adaptive Muon Optimizer](https://arxiv.org/abs/2507.11005).
We now release the core code of AdaMuon. Full project codes will be public in the near future.

## Introduction

AdaMuon is an effective extension of Muon that incorporates a diagonal second-momentum modulation applied to the orthogonalized gradients, and a RMS-aligned rescaling step. 

<img width="861" height="427" alt="截屏2025-07-18 13 04 17" src="https://github.com/user-attachments/assets/eddf691d-437c-40da-b757-7f7d17165686" />


## Performance

AdaMuon can achieve higher training costs reduction compared to Muon.

<img width="864" height="386" alt="截屏2025-07-18 13 06 56" src="https://github.com/user-attachments/assets/62453054-93d4-4455-bc62-419efb7d915d" />
<img width="1664" height="759" alt="截屏2025-07-18 13 07 32" src="https://github.com/user-attachments/assets/f69771c0-3ff2-4c7f-bb24-a38e708479dd" />


## Contact

If you have any questions, suggestions, or feedback, please feel free to contact us at [chongjiesi@sjtu.edu.cn](mailto:chongjiesi@sjtu.edu.cn).

## Citation

If you find this repository useful, please consider giving it a star and citing it in your work:

```bibtex
@article{si2025adamuon,
  title={AdaMuon: Adaptive Muon Optimizer},
  author={Si, Chongjie and Zhang, Debing and Shen, Wei},
  journal={arXiv preprint arXiv:2507.11005},
  year={2025}
}
```
